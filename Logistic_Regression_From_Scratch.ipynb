{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Logistic regression is a fundamental statistical method used for modeling the relationship between a binary dependent variable and one or more independent variables.\n",
    "\n",
    "It's primarily employed for binary classification tasks, where dependent variable takes on only two possible values, typically represented as 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Logistic Regression works\n",
    "\n",
    "Unlike linear regression, which predicts continuous values, logistic regression employs a logistic function to transform the linear combination of independent variables into a probability.\n",
    "\n",
    "`f(x) = 1 / (1 + exp(-x))`\n",
    "\n",
    "The logistic function, also known as the `sigmoid function`, maps input values to a range between 0 and 1, representing the probability of belonging to one class (1) or the other (0). This transformation enables logistic regression to model the probability of a binary outcome rather than a continuous value.\n",
    "\n",
    "By setting a threshold value between 0 and 1, logistic regression classifies data points above the threshold as the other class(0). The choice of threshold influences the trade-off between sentivity and specificity, which respectivity represent the ability to correctly identity postive cases and avoid classifying negative cases as positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions of Logistic Regression:\n",
    "\n",
    "1. Binary Dependent Variable\n",
    "2. Linearity of Independent variables and Log Odds\n",
    "3. Independence of Observations\n",
    "4. No Multicollinearity among independent variables\n",
    "5. No Strong Outliers\n",
    "6. Large Sample size\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalution Metrics for Logistic Regression\n",
    "\n",
    "A confusion matrix is table that summarize the performance of a classification model. It shows the number of correct and incorrect predictions made by the model for each class.\n",
    "\n",
    "1. `True Positive`: The model correctly predicted that an instance belongs to a particular class.\n",
    "2. `True Negative`: The model correctly predicted that an instance does not belong to a particular class.\n",
    "3. `False Positive`: The model incorrectly predicted that an instance belongs to a particular class.\n",
    "4. `False Negative`: The model incorrectly predicted that an instance does not belong to a particular class.\n",
    "\n",
    "The confusion matrix can be used to calculate various evalution metrics, such as accuracy, precision, recall, and F1 score.\n",
    "\n",
    "1. `Accuracy`: It measures the proportion of correct classification made by the model. It is calculated as:\n",
    "   \n",
    "        Accuracy = (True Positives  + True Negatives)/(Total Observations)\n",
    "\n",
    "2. `Precision`: It measures the proportion of true positive predictions among the total positive predictions made by the model. It is calculated as:\n",
    "   \n",
    "        Precision = True Positives / (True Positives + False Positives)\n",
    "\n",
    "3. `Recall`: It measures the proportion of actual positive cases that are correctly identified by the model. It is calculated as:       \n",
    "   \n",
    "        Recall = True Positives / (True Positives + False Negatives)\n",
    "\n",
    "4. `F1 Score`: It is a harmonic mean of precision and recall. It is calculated as:\n",
    "   \n",
    "        F1 Score = 2 * (Precision * Recall) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation from Scratch using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5882841  0.81074467 0.92776379]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate, n_epochs):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_epochs = n_epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        predictions = self.sigmoid(z)\n",
    "        return predictions\n",
    "\n",
    "    def train(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.random.randn(n_features)\n",
    "        self.bias = np.random.randn()\n",
    "\n",
    "        #Training loop\n",
    "        for epoch in range(self.n_epochs):\n",
    "            # Calculate predictions\n",
    "            predictions = self. predict(X)\n",
    "\n",
    "            #Calculate gradient\n",
    "            gradient_weights = np.dot(X.T, (predictions -y)) / n_samples\n",
    "            gradient_bias = np.mean(predictions - y)\n",
    "\n",
    "            #update weights and bias\n",
    "            self.weights -= self.learning_rate * gradient_weights\n",
    "            self.bias -= self.learning_rate * gradient_bias\n",
    "\n",
    "#Example usage\n",
    "X = np.array([[1,2], [3,4], [5,6]])\n",
    "y = np.array([0,1, 1])\n",
    "\n",
    "model = LogisticRegression(learning_rate=0.01, n_epochs=100)\n",
    "model.train(X, y)\n",
    "\n",
    "predictions = model.predict(X)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
